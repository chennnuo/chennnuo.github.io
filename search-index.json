[{"content":"Well-thought-through product announcements will help increase feature awareness and engage users with new functionality. Just like sharing your public roadmap, it\u0026rsquo;s also a great way to let potential customers see that you\u0026rsquo;re constantly improving.\nFurther reading Read How to announce product updates and features ","date":"2023-09-07","id":0,"permalink":"/blog/example-post/","summary":"You can use blog posts for announcing product updates and features.","tags":[],"title":"Example Post"},{"content":"","date":"2023-09-07","id":1,"permalink":"/blog/","summary":"","tags":[],"title":"Blog"},{"content":"","date":"2023-09-07","id":2,"permalink":"/docs/introduction/","summary":"","tags":[],"title":"Introduction"},{"content":"","date":"2023-09-07","id":3,"permalink":"/docs/linux/","summary":"","tags":[],"title":"Linux"},{"content":"","date":"2023-09-07","id":4,"permalink":"/docs/mmcv/","summary":"","tags":[],"title":"MMCV"},{"content":"","date":"2023-09-07","id":5,"permalink":"/docs/notes/","summary":"","tags":[],"title":"Notes"},{"content":"Runner Runner是算法训练部分的引擎，其核心功能和特性如下：\n负责MMCV中所有框架的训练过程调度\n支持定制工作流以满足训练过程中的各状态自由切换\n提供了Epoch和Iter为基础的迭代模式，以满足不同的场景\n配合各类Hook，对外提供了灵活的拓展能力，注入不同Hook可在训练过程中优雅的实现拓展功能\n运行步骤 Runner对象初始化\n注册各类 Hook 到 Runner 中\n调用 Runner 中的 rusume 或者 load_checkpoint 方法对权重进行加载\n运行给定的工作流，此时才真正开始了工作流\n1. Runner初始化 为了复用，抽象出一个 BaseRunner，常规初始化如下：\ndef __init__(self, model, batch_processor=None, # 已废弃 optimizer=None, work_dir=None, logger=None, meta=None, # 提供了该参数，则会保存到 ckpt 中 max_iters=None, # 这两个参数非常关键，如果没有给定，则内部自己计算 max_epochs=None):\r2. 注册Hook register_training_hooks，其作用是注册一些默认 Hook，如下所示：\ndef register_training_hooks(self, lr_config, # lr相关 optimizer_config=None, # 优化器相关 checkpoint_config=None, # ckpt 保存相关 log_config=None, # 日志记录相关 momentum_config=None, # momentum 相关 timer_config=dict(type=\u0026#39;IterTimerHook\u0026#39;)) # 迭代时间统计\r内部会自动解析这些配置，生成对应 Hook，并且注册到 Runner 中。\nregister_hook，除了上面这些 Hook 外，其他所有 Hook，都是通过本方式注入，例如 eval_hook、custom_hooks 和 DistSamplerSeedHook 等等。其内部实现是将 Hook 类实例按照优先级插入 _hooks 列表中，运行时候会顺序调用。\ndef register_hook(self, hook, priority=\u0026#39;NORMAL\u0026#39;): # 获取优先级 priority = get_priority(priority) hook.priority = priority # 基于优先级计算当前 hook 插入位置 inserted = False for i in range(len(self._hooks) - 1, -1, -1): if priority \u0026gt;= self._hooks[i].priority: self._hooks.insert(i + 1, hook) inserted = True break if not inserted: self._hooks.insert(0, hook)\r3. resume 和load_checkpoint resume 方法用于训练过程中停止然后恢复训练时加载权重，而 load_checkpoint 仅仅是加载预训练权重而已，这个预训练权重可以来自官方，也可以来自自己训练后的权重，如果有 key 不匹配的参数则会自动跳过。\n4. run 以EpochBasedRunner run 为例\ndef run(self, data_loaders, # dataloader 列表 workflow, # 工作流列表，长度需要和 data_loaders 一致 max_epochs=None, **kwargs):\r假设只想运行训练工作流，则可以设置 workflow = [(\u0026rsquo;train\u0026rsquo;, 1)]，表示 data_loader 中的数据进行迭代训练\n假设想运行训练和验证工作流，则可以设置 workflow = [(\u0026rsquo;train\u0026rsquo;, 3), (\u0026lsquo;val\u0026rsquo;,1)]，表示先训练 3 个 epoch ，然后切换到 val 工作流，运行 1 个 epoch，然后循环，直到训练 epoch 次数达到指定值\n工作流设置非常自由，例如你可以先验证再训练 workflow = [(\u0026lsquo;val\u0026rsquo;, 1), (\u0026rsquo;train\u0026rsquo;,1)]\n需要注意的是：如果工作流有两个，那么 data_loaders 中也需要提供两个 dataloader。其核心逻辑如下：\ndef run(self, data_loaders, workflow, max_epochs=None, **kwargs): assert isinstance(data_loaders, list) assert mmcv.is_list_of(workflow, tuple) assert len(data_loaders) == len(workflow) # epoch 模式，需要自动计算出 _max_iters for i, flow in enumerate(workflow): mode, epochs = flow if mode == \u0026#39;train\u0026#39;: self._max_iters = self._max_epochs * len(data_loaders[i]) break # 调用注册到 runner 中的所有 hook 的 before_run 方法，表示开启 run 前 self.call_hook(\u0026#39;before_run\u0026#39;) # 如果没有达到退出条件，就一直运行工作流 while self.epoch \u0026lt; self._max_epochs: # 遍历工作流 for i, flow in enumerate(workflow): # 模式，和当前工作流需要运行的 epoch 次数 mode, epochs = flow epoch_runner = getattr(self, mode) for _ in range(epochs): if mode == \u0026#39;train\u0026#39; and self.epoch \u0026gt;= self._max_epochs: break # 开始一个 epoch 的迭代 epoch_runner(data_loaders[i], **kwargs) time.sleep(1) # wait for some hooks like loggers to finish # 调用注册到 runner 中的所有 hook 的 after_run 方法，表示结束 run 后 self.call_hook(\u0026#39;after_run\u0026#39;)\r可以看法 run 方法中定义的是通用工作流切换流程，真正完成一个 epoch 工作流是调用了工作流函数。目前支持 train 和 val 两个工作流，那么 epoch_runner(data_loaders[i], **kwargs) 调用的实际上是 train 或者 val 方法：\n# train 和 val 方法逻辑非常相似 def train(self, data_loader, **kwargs): self.model.train() self.mode = \u0026#39;train\u0026#39; self.data_loader = data_loader self._max_iters = self._max_epochs * len(self.data_loader) self.call_hook(\u0026#39;before_train_epoch\u0026#39;) time.sleep(2) # Prevent possible deadlock during epoch transition for i, data_batch in enumerate(self.data_loader): self._inner_iter = i self.call_hook(\u0026#39;before_train_iter\u0026#39;) self.run_iter(data_batch, train_mode=True) self.call_hook(\u0026#39;after_train_iter\u0026#39;) self._iter += 1 self.call_hook(\u0026#39;after_train_epoch\u0026#39;) self._epoch += 1 @torch.no_grad() def val(self, data_loader, **kwargs): self.model.eval() self.mode = \u0026#39;val\u0026#39; self.data_loader = data_loader self.call_hook(\u0026#39;before_val_epoch\u0026#39;) time.sleep(2) # Prevent possible deadlock during epoch transition for i, data_batch in enumerate(self.data_loader): self._inner_iter = i self.call_hook(\u0026#39;before_val_iter\u0026#39;) self.run_iter(data_batch, train_mode=False) self.call_hook(\u0026#39;after_val_iter\u0026#39;) self.call_hook(\u0026#39;after_val_epoch\u0026#39;)\r上述逻辑是遍历 data_loader，然后进行 batch 级别的迭代训练或者验证，比较容易理解。真正完成一个 batch 的训练或者验证是调用了 self.run_iter ：\n# 简化逻辑 def run_iter(self, data_batch, train_mode, **kwargs): # 调用 model 自身的 train_step 或者 val_step 方法 if train_mode: outputs = self.model.train_step(data_batch, self.optimizer, **kwargs) else: outputs = self.model.val_step(data_batch, self.optimizer, **kwargs) if \u0026#39;log_vars\u0026#39; in outputs: self.log_buffer.update(outputs[\u0026#39;log_vars\u0026#39;], outputs[\u0026#39;num_samples\u0026#39;]) self.outputs = outputs\r由于 IterBasedRunner 模式没有 epoch 的概念，故 IterBasedRunner 的 run 方法有些许改动\n工作流终止条件不再是 epoch，而是 iter\nHook 的生命周期方法也不涉及 epoch，全部是 iter 相关方法\n虽然本类中不需要 epoch 参数，但是 epoch 参数在很多场景比较有用，故还是需要通过 IterLoader 得到\nclass IterLoader: def __init__(self, dataloader): self._dataloader = dataloader self.iter_loader = iter(self._dataloader) self._epoch = 0 @property def epoch(self): return self._epoch def __next__(self): try: data = next(self.iter_loader) except StopIteration: # 迭代完一次，就表示一个 epoch 完成 self._epoch += 1 # 保证分布式场景下，一个 epoch 内部各个卡的随机是确定的 if hasattr(self._dataloader.sampler, \u0026#39;set_epoch\u0026#39;): self._dataloader.sampler.set_epoch(self._epoch) # 开启下一次迭代 self.iter_loader = iter(self._dataloader) data = next(self.iter_loader) return data def __len__(self): return len(self._dataloader)\r假设数据长度是 1024，batch=4，那么 dataloader 长度是 1024/4=256, 也就是一个 epoch 是 256 次迭代，在 Iter 训练模式下，计划训练 100000 个迭代，那么实际上运行了 100000//256=39 个 epoch。\n","date":"2024-11-18","id":6,"permalink":"/docs/mmcv/mmcv-runner/","summary":"Runner Runner是算法训练部分的引擎，其核心功能和特性如下：\n负责MMCV中所有框架的训练过程调度\n支持定制工作流以满足训练过程中的各状态自由切换\n提供了Epoch和Iter为基础的迭代模式，以满足不同的场景\n配合各类Hook，对外提供了灵活的拓展能力，注入不同Hook可在训练过程中优雅的实现拓展功能\n运行步骤 Runner对象初始化\n注册各类 Hook 到 Runner 中\n调用 Runner 中的 rusume 或者 load_checkpoint 方法对权重进行加载","tags":[],"title":"MMCV-Runner"},{"content":"0. 参考资料 Video 动画形式直观解释注意力机制 1. Attention机制概述 Attention机制是Transformer架构的核心,它使模型能够动态地关注输入序列中的不同部分。这种机制允许模型捕捉长距离依赖关系,这在处理长序列时特别重要。\n2. Self-Attention的基本概念 Self-Attention的核心思想是,序列中的每个元素都应该关注整个序列,包括自身。它通过以下三个关键概念实现:\nQuery (查询): 当前我们正在处理的元素 Key (键): 用于与Query进行比较的元素 Value (值): 实际被聚合的信息 以NLP任务为例，Value 是前面这些词最终想要加给下一个单词的的偏移量，目标是得到 Q \u0026ndash;\u0026gt; V 的映射，这个映射主要用来压缩前后文信息，加到当前word上。\n3. Self-Attention的计算过程 Self-Attention的计算可以概括为以下步骤：\n对输入进行线性变换,得到Q、K、V矩阵。 计算Q和K的点积,得到注意力分数。 对注意力分数进行缩放和softmax归一化。 用归一化后的分数对V进行加权求和。 数学表达式为:\n其中\r是键向量的维度，\r用于缩放以防止点积结果过大。\n4. Attention的直观理解 可以将Attention理解为一种软性的字典查找。Query就像是一个搜索词,Keys像是字典中的条目,而Values则是对应的内容。模型通过计算Query和Keys的相似度来决定应该关注哪些Values。\n5. Attention的应用示例 在机器翻译中,Attention允许模型在生成每个目标词时动态地关注源句子的不同部分。例如,翻译\u0026quot;The cat sat on the mat\u0026quot;时,在生成\u0026quot;猫\u0026quot;这个词时,模型会更多地关注源句中的\u0026quot;cat\u0026quot;。\n6. Attention的变体和扩展 除了基本的Self-Attention,还有许多变体,如:\nRelative Position Attention: 引入相对位置信息 Sparse Attention: 通过稀疏化提高效率 Longformer: 处理更长序列的注意力机制 总的来说,Attention机制使Transformer能够灵活地处理序列数据,捕捉复杂的上下文关系,这是其在多种NLP任务上取得卓越性能的关键原因。\n7. 自问自答 7.1 为什么要除根号dk 缩放的必要性：\n首先，在Attention计算中，我们对Q和K进行点积操作。当输入的维度d_k较大时，点积的结果可能会变得非常大。这会导致softmax函数的梯度变得极小，造成所谓的梯度消失问题，影响模型的训练。\n为什么是\r选择\r作为缩放因子主要是为了保持方差的稳定性。这里涉及到一些统计学原理：\n假设Q和K中的元素是独立同分布的随机变量，均值为0，方差为1。 在这种情况下，它们的点积\r的方差将等于\r。 通过除以\r，我们可以将点积的方差归一化为1。 这种归一化确保了无论输入的维度如何变化，注意力分数的分布都保持相对稳定。 为什么不使用其他值\n如果不进行缩放（即除以1），当$d_k$较大时，点积结果可能会非常大，导致softmax后的注意力分布过于集中。 如果除以$d_k$，可能会使结果变得过小，特别是当d_k较大时，这可能导致梯度过小，影响模型的学习。 其他的缩放因子（如$d_k^{\\frac{1}{3}}$或$2d_k$）可能无法有效地控制方差，或者没有明确的统计学解释。 实践经验\n在实际应用中，使用$\\sqrt{d_k}$作为缩放因子已经在多个任务和模型中证明了其有效性。它提供了一个很好的平衡点，既能控制方差，又不会过度压缩注意力分数。 这种缩放方法的理论基础可以追溯到Xavier初始化和He初始化等神经网络权重初始化方法。这些方法同样使用了$\\sqrt{d_k}$（n为输入单元数）来保持前向传播时激活值的方差稳定。 值得注意的是，尽管$\\sqrt{d_k}$是一个很好的默认选择，但在某些特定任务或模型结构中，可能会使用略有不同的缩放因子。这取决于具体的应用场景和实验结果。 总的来说，使用$\\sqrt{d_k}$作为缩放因子是基于统计学原理的选择，旨在保持注意力机制在不同维度下的稳定性和有效性。这个选择在理论上有合理的解释，并在实践中证明了其有效性。\n疑惑2，为什么当输入的维度d_k较大时，点积的结果可能会变得非常大\n点积的基本性质 首先，让我们回顾一下点积的定义。对于两个向量 a = [a₁, a₂, \u0026hellip;, aₙ] 和 b = [b₁, b₂, \u0026hellip;, bₙ]，它们的点积是： $a \\cdot b = a_1b_1 + a_2b_2 + \u0026hellip; + a_nb_n$ ","date":"2024-11-18","id":7,"permalink":"/docs/notes/what-is-attention/","summary":"0. 参考资料 Video 动画形式直观解释注意力机制 1. Attention机制概述 Attention机制是Transformer架构的核心,它使模型能够动态地关注输入序列中的不同部分。这种机制允许模型捕捉长距离依赖关系,这在处理长序列时特别重要。\n2. Self-Attention的基本概念 Self-Attention的核心思想是,序列中的每个元素都应该关注整个序列,包括自身。它通过以下三个关键概念实现:\nQuery (查询): 当前我们正在处理的元素 Key (键): 用于与Query进行比较的元素 Value (值): 实际被聚合的信息 以NLP任务为例，Value 是前面这些词最终想要加给下一个单词的的偏移量，目标是得到 Q \u0026ndash;\u0026gt; V 的映射，这个映射主要用来压缩前后文信息，加到当前word上。","tags":[],"title":"What is Attention"},{"content":"这里是我的个人笔记网站 欢迎大家访问！\n关键 shell 命令 生成网页 生成本地网页\rnpm run dev\r创建新md 创建新的文件\rnpm run create docs/notes/Attention.md\r","date":"2023-09-07","id":8,"permalink":"/docs/introduction/introduction/","summary":"这里是我的个人笔记网站 欢迎大家访问！\n关键 shell 命令 生成网页 生成本地网页\rnpm run dev\r创建新md 创建新的文件\rnpm run create docs/notes/Attention.md\r","tags":[],"title":"introduction"},{"content":"Linux 实用小技巧\nFurther reading Read about how-to guides in the Diátaxis framework ","date":"2023-09-07","id":9,"permalink":"/docs/linux/linux/","summary":"Linux 实用小技巧\nFurther reading Read about how-to guides in the Diátaxis framework ","tags":[],"title":"Linux"},{"content":"Registry Registry可以提供一种完全相似的对外装饰函数来管理构建不同组件 例如：backbone、head、neck等 其实内部实现是一个全局的key-value对 优点是可以通过字符串实例化任何想要的模块、解耦性强、可扩展性强，代码更易理解。\n# 例如Faster R-CNN的backbone： backbone=dict( type=\u0026#39;ResNet\u0026#39;, # 待实例化的类名 depth=50, # 后面的都是对于的类初始化参数 num_stages=4, out_indices=(0, 1, 2, 3), frozen_stages=1, norm_cfg=dict(type=\u0026#39;BN\u0026#39;, requires_grad=True), norm_eval=True, style=\u0026#39;pytorch\u0026#39;),\r主要是注册器类Registry()和函数register_module() 简单实现类似于：\n_module_dict = dict() # 定义装饰器函数 def register_module(name): def _register(cls): _module_dict[name] = cls return cls return _register # 装饰器用法 @register_module(\u0026#39;one_class\u0026#39;) class OneTest(object): pass @register_module(\u0026#39;two_class\u0026#39;) class TwoTest(object): pass\r具体实现(删减)： class Registry: def __init__(self, name, build_func=None, parent=None, scope=None): self._name = name self._module_dict = dict() def _register_module(self, module_class, module_name=None, force=False): if not inspect.isclass(module_class): raise TypeError(\u0026#39;module must be a class, \u0026#39; f\u0026#39;but got {type(module_class)}\u0026#39;) if module_name is None: module_name = module_class.__name__ if isinstance(module_name, str): module_name = [module_name] for name in module_name: if not force and name in self._module_dict: raise KeyError(f\u0026#39;{name} is already registered \u0026#39; f\u0026#39;in {self.name}\u0026#39;) self._module_dict[name] = module_class def register_module(self, name=None, force=False, module=None): if not isinstance(force, bool): raise TypeError(f\u0026#39;force must be a boolean, but got {type(force)}\u0026#39;) # NOTE: This is a walkaround to be compatible with the old api, # while it may introduce unexpected bugs. if isinstance(name, type): return self.deprecated_register_module(name, force=force) # raise the error ahead of time if not (name is None or isinstance(name, str) or is_seq_of(name, str)): raise TypeError( \u0026#39;name must be either of None, an instance of str or a sequence\u0026#39; f\u0026#39; of str, but got {type(name)}\u0026#39;) # use it as a normal method: x.register_module(module=SomeClass) if module is not None: self._register_module( module_class=module, module_name=name, force=force) return module # use it as a decorator: @x.register_module() def _register(cls): self._register_module( module_class=cls, module_name=name, force=force) return cls return _register\r类的实例化都是通过build_from_cfg()实现 def build_from_cfg(config, registry, default_args=None): if not isinstance(config, dict): raise TypeError(\u0026#39;config must be a dict, but got {}\u0026#39;.format( type(config))) if \u0026#39;type\u0026#39; not in config: if default_args is None or \u0026#39;type\u0026#39; not in default_args: raise KeyError( \u0026#39;The config has no field named \u0026#34;type\u0026#34; and default_args has no \u0026#39; \u0026#39;\u0026#34;type\u0026#34; field either\u0026#39;) if not isinstance(registry, Registry): raise TypeError(\u0026#39;registry must be an instance of Registry, but got \u0026#39; \u0026#39;{}\u0026#39;.format(type(registry))) if not (isinstance(default_args, dict) or default_args is None): raise TypeError(\u0026#39;default_args must be a dict or None, but got {}\u0026#39;.format( type(default_args))) args = config.copy() if default_args is not None: for name, value in default_args.items(): args.setdefault(name, value) obj_type = args.pop(\u0026#39;type\u0026#39;) if isinstance(obj_type, str): obj_cls = registry.get(obj_type) if obj_cls is None: raise KeyError(f\u0026#39;{obj_type} is not in the {registry.name} registry\u0026#39;) elif inspect.isclass(obj_type): obj_cls = obj_type else: raise TypeError(f\u0026#39;type must be a str or valid type, but got {type(obj_type)}\u0026#39;) try: return obj_cls(**args) except Exception as e: raise type(e)(f\u0026#39;{obj_cls.__name__} : {e}\u0026#39;)\r使用案例： CONVERTERS = Registry(\u0026#39;converter\u0026#39;) @CONVERTERS.register_module() class Converter1(object): def __init__(self, a, b): self.a = a self.b = b converter_cfg = dict(type=\u0026#39;Converter1\u0026#39;, a=a_value, b=b_value) converter = build_from_cfg(converter_cfg,CONVERTERS)\r","date":"2023-09-07","id":10,"permalink":"/docs/mmcv/mmcv-registry/","summary":"Registry Registry可以提供一种完全相似的对外装饰函数来管理构建不同组件 例如：backbone、head、neck等 其实内部实现是一个全局的key-value对 优点是可以通过字符串实例化任何想要的模块、解耦性强、可扩展性强，代码更易理解。\n# 例如Faster R-CNN的backbone： backbone=dict( type=\u0026#39;ResNet\u0026#39;, # 待实例化的类名 depth=50, # 后面的都是对于的类初始化参数 num_stages=4, out_indices=(0, 1, 2, 3), frozen_stages=1, norm_cfg=dict(type=\u0026#39;BN\u0026#39;, requires_grad=True), norm_eval=True, style=\u0026#39;pytorch\u0026#39;),\r主要是注册器类Registry()和函数register_module() 简单实现类似于：","tags":[],"title":"MMCV-Registry"},{"content":"","date":"2023-09-07","id":11,"permalink":"/docs/reference/","summary":"","tags":[],"title":"Reference"},{"content":"Reference pages are ideal for outlining how things work in terse and clear terms. Less concerned with telling a story or addressing a specific use case, they should give a comprehensive outline of what your documenting.\nFurther reading Read about reference in the Diátaxis framework ","date":"2023-09-07","id":12,"permalink":"/docs/reference/example-reference/","summary":"Reference pages are ideal for outlining how things work in terse and clear terms. Less concerned with telling a story or addressing a specific use case, they should give a comprehensive outline of what your documenting.","tags":[],"title":"Example Reference"},{"content":"Link to valuable, relevant resources.\n","date":"2024-02-27","id":13,"permalink":"/docs/resources/","summary":"Link to valuable, relevant resources.","tags":[],"title":"Resources"},{"content":"","date":"2023-09-07","id":14,"permalink":"/docs/","summary":"","tags":[],"title":"Docs"},{"content":"","date":"2023-09-07","id":15,"permalink":"/connect-to-me/","summary":"","tags":[],"title":"Connect to me"},{"content":"","date":"2023-09-07","id":16,"permalink":"/","summary":"","tags":[],"title":"Welcome to My Notes Web！"},{"content":"","date":"0001-01-01","id":17,"permalink":"/categories/","summary":"","tags":[],"title":"Categories"},{"content":"","date":"0001-01-01","id":18,"permalink":"/contributors/","summary":"","tags":[],"title":"Contributors"},{"content":"","date":"0001-01-01","id":19,"permalink":"/tags/","summary":"","tags":[],"title":"Tags"}]