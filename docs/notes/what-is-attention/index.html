<!doctype html><html lang=en data-bs-theme=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1"><link rel=preload href=https://chennnuo.github.io/fonts/vendor/jost/jost-v4-latin-regular.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=https://chennnuo.github.io/fonts/vendor/jost/jost-v4-latin-500.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=https://chennnuo.github.io/fonts/vendor/jost/jost-v4-latin-700.woff2 as=font type=font/woff2 crossorigin><script src=/js/color-mode.86a91f050a481d0a3f0c72ac26543cb6228c770875981c58dcbc008fd3f875c8.js integrity="sha256-hqkfBQpIHQo/DHKsJlQ8tiKMdwh1mBxY3LwAj9P4dcg="></script><link rel=stylesheet href="/main.62b45e0e201d1b5dbc5f66480830a3d8c2fc4dc8f3561903dac9c4d61947d832e2b5cf53bbf6532339037f20054695c2c2c30492b65f7d426a992b240adc3805.css" integrity="sha512-YrReDiAdG128X2ZICDCj2ML8TcjzVhkD2snE1hlH2DLitc9Tu/ZTIzkDfyAFRpXCwsMEkrZffUJqmSskCtw4BQ==" crossorigin=anonymous><noscript><style>img.lazyload{display:none}</style></noscript><base href=https://chennnuo.github.io/docs/notes/what-is-attention/><link rel=canonical href=https://chennnuo.github.io/docs/notes/what-is-attention/><title>What is Attention | My Docs</title>
<meta name=description content="一篇解释 Attention 注意力机制的笔记."><link rel=icon href=/favicon.ico sizes=32x32><link rel=icon href=/favicon.svg type=image/svg+xml><link rel=apple-touch-icon href=/apple-touch-icon.png sizes=180x180 type=image/png><link rel=icon href=/favicon-192x192.png sizes=192x192 type=image/png><link rel=icon href=/favicon-512x512.png sizes=512x512 type=image/png><link rel=manifest href=/manifest.webmanifest><meta property="og:url" content="https://chennnuo.github.io/docs/notes/what-is-attention/"><meta property="og:site_name" content="My Docs"><meta property="og:title" content="What is Attention"><meta property="og:description" content="一篇解释 Attention 注意力机制的笔记."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="docs"><meta property="article:published_time" content="2024-11-18T14:20:00+08:00"><meta property="article:modified_time" content="2024-11-18T14:20:00+08:00"><meta property="og:image" content="https://chennnuo.github.io/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://chennnuo.github.io/cover.png"><meta name=twitter:title content="What is Attention"><meta name=twitter:description content="一篇解释 Attention 注意力机制的笔记."><meta name=twitter:site content="@getdoks"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","item":"https://chennnuo.github.io/","name":"Welcome to My Notes Web！","position":1},{"@type":"ListItem","item":"https://chennnuo.github.io/docs/","name":"Docs","position":2},{"@type":"ListItem","item":"https://chennnuo.github.io/docs/notes/","name":"Notes","position":3},{"@type":"ListItem","name":"What Is Attention","position":4}]}</script></head><body class="single section docs" data-bs-spy=scroll data-bs-target=#toc data-bs-root-margin="0px 0px -60%" data-bs-smooth-scroll=true tabindex=0><div class=sticky-top><header class="navbar navbar-expand-lg"><div class=container-lg><a class="navbar-brand me-auto me-lg-3" href=/>My Docs</a>
<button type=button id=searchToggleMobile class="btn btn-link nav-link mx-2 d-lg-none" aria-label="Search website">
<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
</button>
<button class="btn btn-link d-lg-none" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasNavSection aria-controls=offcanvasNavSection aria-label="Open section navigation menu"><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-dots-vertical" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 12m-1 0a1 1 0 102 0 1 1 0 10-2 0"/><path d="M12 19m-1 0a1 1 0 102 0 1 1 0 10-2 0"/><path d="M12 5m-1 0a1 1 0 102 0 1 1 0 10-2 0"/></svg></button><div class="offcanvas offcanvas-start d-lg-none" tabindex=-1 id=offcanvasNavSection aria-labelledby=offcanvasNavSectionLabel><div class=offcanvas-header><h5 class=offcanvas-title id=offcanvasNavSectionLabel>Docs</h5><button type=button class="btn btn-link nav-link p-0 ms-auto" data-bs-dismiss=offcanvas aria-label=Close><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-x" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M18 6 6 18"/><path d="M6 6l12 12"/></svg></button></div><div class=offcanvas-body><aside class="doks-sidebar mt-n3"><nav id=doks-docs-nav aria-label="Tertiary navigation"><nav class="section-nav docs-links"><ul class=list-unstyled><li><details open><summary>Introduction</summary><ul class="list-unstyled list-nested"><li><a href=/docs/introduction/introduction/>introduction</a></li></ul></details></li><li><details open><summary>Linux</summary><ul class="list-unstyled list-nested"><li><a href=/docs/linux/linux/>Linux</a></li></ul></details></li><li><details open><summary>MMCV</summary><ul class="list-unstyled list-nested"><li><a href=/docs/mmcv/mmcv-runner/>MMCV-Runner</a></li><li><a href=/docs/mmcv/mmcv-registry/>MMCV-Registry</a></li></ul></details></li><li><details open open><summary>Notes</summary><ul class="list-unstyled list-nested"><li class=active><a aria-current=page href=/docs/notes/what-is-attention/>What is Attention</a></li></ul></details></li><li><details><summary>Reference</summary><ul class="list-unstyled list-nested"><li><a href=/docs/reference/example-reference/>Example Reference</a></li></ul></details></li></ul></nav></nav></aside></div></div><button class="btn btn-link nav-link mx-2 order-3 d-lg-none" type=button data-bs-toggle=offcanvas data-bs-target=#offcanvasNavMain aria-controls=offcanvasNavMain aria-label="Open main navigation menu"><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-menu" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><line x1="4" y1="8" x2="20" y2="8"/><line x1="4" y1="16" x2="20" y2="16"/></svg></button><div class="offcanvas offcanvas-end h-auto" tabindex=-1 id=offcanvasNavMain aria-labelledby=offcanvasNavMainLabel><div class=offcanvas-header><h5 class=offcanvas-title id=offcanvasNavMainLabel>My Docs</h5><button type=button class="btn btn-link nav-link p-0 ms-auto" data-bs-dismiss=offcanvas aria-label=Close><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-x" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M18 6 6 18"/><path d="M6 6l12 12"/></svg></button></div><div class="offcanvas-body d-flex flex-column flex-lg-row justify-content-between"><ul class="navbar-nav flex-grow-1"><li class=nav-item><a class="nav-link active" href=https://chennnuo.github.io/docs/introduction/introduction/ aria-current=true>Docs</a></li><li class=nav-item><a class=nav-link href=https://chennnuo.github.io/blog/>Blog</a></li></ul><button type=button id=searchToggleDesktop class="btn btn-link nav-link p-2 d-none d-lg-block" aria-label="Search website">
<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
</button>
<button id=buttonColorMode class="btn btn-link mx-auto nav-link p-0 ms-lg-2 me-lg-1" type=button aria-label="Toggle theme"><svg data-bs-theme-value="dark" xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-moon" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 3c.132.0.263.0.393.0a7.5 7.5.0 007.92 12.446A9 9 0 1112 2.992z"/></svg><svg data-bs-theme-value="light" xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-sun" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M12 12m-4 0a4 4 0 108 0 4 4 0 10-8 0m-5 0h1m8-9v1m8 8h1m-9 8v1M5.6 5.6l.7.7m12.1-.7-.7.7m0 11.4.7.7m-12.1-.7-.7.7"/></svg></button><ul id=socialMenu class="nav mx-auto flex-row order-lg-4"><li class=nav-item><a class="nav-link social-link" href=https://github.com/thuliteio/doks><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg><small class="ms-2 visually-hidden">GitHub</small></a></li></ul></div></div></div></header></div><div class=modal id=searchModal tabindex=-1 aria-labelledby=searchModalLabel aria-hidden=true><div class="modal-dialog modal-dialog-scrollable modal-fullscreen-md-down"><div class=modal-content><div class=modal-header><h1 class="modal-title fs-5 visually-hidden" id=searchModalLabel>Search</h1><button type=button class="btn-close visually-hidden" data-bs-dismiss=modal aria-label=Close></button><div class="search-input flex-grow-1 d-none"><form id=search-form class=search-form action=# method=post accept-charset=UTF-8 role=search><label for=query class=visually-hidden>Search</label><div class=d-flex><input type=search id=query name=query class="search-text form-control form-control-lg" placeholder=Search aria-label=Search maxlength=128 autocomplete=off>
<button type=button class="btn btn-link text-decoration-none px-0 ms-3 d-md-none" data-bs-dismiss=modal aria-label=Close>Cancel</button></div></form></div></div><div class=modal-body><p class="search-loading status message d-none mt-3 text-center">Loading search index…</p><p class="search-no-recent message d-none mt-3 text-center">No recent searches</p><p class="search-no-results message d-none mt-3 text-center">No results for "<strong><span class=query-no-results>Query here</span></strong>"</p><div id=searchResults class=search-results></div><template><article class="search-result list-view"><div class="card my-3"><div class=card-body><header><h2 class="h5 title title-submitted mb-0"><a class="stretched-link text-decoration-none text-reset" href=#>Title here</a></h2><div class="submitted d-none"><time class=created-date>Date here</time></div></header><div class=content>Summary here</div></div></div></article></template></div><div class=modal-footer><ul class="list-inline me-auto d-none d-md-block"><li class=list-inline-item><kbd class=me-2><svg width="15" height="15" aria-label="Enter key" role="img"><g fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M12 3.53088v3c0 1-1 2-2 2H4m3 3-3-3 3-3"/></g></svg></kbd><span class=DocSearch-Label>to select</span></li><li class=list-inline-item><kbd class=me-2><svg width="15" height="15" aria-label="Arrow down" role="img"><g fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M7.5 3.5v8m3-3-3 3-3-3"/></g></svg></kbd><kbd class=me-2><svg width="15" height="15" aria-label="Arrow up" role="img"><g fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M7.5 11.5v-8m3 3-3-3-3 3"/></g></svg></kbd><span class=DocSearch-Label>to navigate</span></li><li class=list-inline-item><kbd class=me-2><svg width="15" height="15" aria-label="Escape key" role="img"><g fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.2"><path d="M13.6167 8.936c-.1065.3583-.6883.962-1.4875.962-.7993.0-1.653-.9165-1.653-2.1258v-.5678c0-1.2548.7896-2.1016 1.653-2.1016s1.3601.4778 1.4875 1.0724M9 6c-.1352-.4735-.7506-.9219-1.46-.8972-.7092.0246-1.344.57-1.344 1.2166s.4198.8812 1.3445.9805C8.465 7.3992 8.968 7.9337 9 8.5s-.454 1.398-1.4595 1.398C6.6593 9.898 6 9 5.963 8.4851m-1.4748.5368c-.2635.5941-.8099.876-1.5443.876s-1.7073-.6248-1.7073-2.204v-.4603c0-1.0416.721-2.131 1.7073-2.131.9864.0 1.6425 1.031 1.5443 2.2492h-2.956"/></g></svg></kbd><span class=DocSearch-Label>to close</span></li></ul><p class=d-md-none>Search by <a class=text-decoration-none href=https://github.com/nextapps-de/flexsearch>FlexSearch</a></p></div></div></div></div><div class="wrap container-lg" role=document><div class=content><div class="row flex-xl-nowrap"><div class="col-lg-5 col-xl-4 docs-sidebar d-none d-lg-block"><nav class="section-nav docs-links"><ul class=list-unstyled><li><details open><summary>Introduction</summary><ul class="list-unstyled list-nested"><li><a href=/docs/introduction/introduction/>introduction</a></li></ul></details></li><li><details open><summary>Linux</summary><ul class="list-unstyled list-nested"><li><a href=/docs/linux/linux/>Linux</a></li></ul></details></li><li><details open><summary>MMCV</summary><ul class="list-unstyled list-nested"><li><a href=/docs/mmcv/mmcv-runner/>MMCV-Runner</a></li><li><a href=/docs/mmcv/mmcv-registry/>MMCV-Registry</a></li></ul></details></li><li><details open open><summary>Notes</summary><ul class="list-unstyled list-nested"><li class=active><a aria-current=page href=/docs/notes/what-is-attention/>What is Attention</a></li></ul></details></li><li><details><summary>Reference</summary><ul class="list-unstyled list-nested"><li><a href=/docs/reference/example-reference/>Example Reference</a></li></ul></details></li></ul></nav></div><nav class="docs-toc d-none d-xl-block col-xl-3" aria-label="Secondary navigation"><div class=page-links><h3>On this page</h3><nav id=toc><ul><li><a href=#0-参考资料>0. 参考资料</a></li><li><a href=#1-attention机制概述>1. Attention机制概述</a></li><li><a href=#2-self-attention的基本概念>2. Self-Attention的基本概念</a></li><li><a href=#3-self-attention的计算过程>3. Self-Attention的计算过程</a></li><li><a href=#4-attention的直观理解>4. Attention的直观理解</a></li><li><a href=#5-attention的应用示例>5. Attention的应用示例</a></li><li><a href=#6-attention的变体和扩展>6. Attention的变体和扩展</a></li><li><a href=#7-自问自答>7. 自问自答</a><ul><li><a href=#71-为什么要除根号dk>7.1 为什么要除根号dk</a></li></ul></li></ul></nav></div></nav><main class="docs-content col-lg-11 col-xl-9"><h1>What is Attention</h1><nav class="toc-mobile d-xl-none" aria-label="Quaternary navigation"><details><summary>On this page</summary><div class=page-links><nav id=TableOfContents><ul><li><a href=#0-参考资料>0. 参考资料</a></li><li><a href=#1-attention机制概述>1. Attention机制概述</a></li><li><a href=#2-self-attention的基本概念>2. Self-Attention的基本概念</a></li><li><a href=#3-self-attention的计算过程>3. Self-Attention的计算过程</a></li><li><a href=#4-attention的直观理解>4. Attention的直观理解</a></li><li><a href=#5-attention的应用示例>5. Attention的应用示例</a></li><li><a href=#6-attention的变体和扩展>6. Attention的变体和扩展</a></li><li><a href=#7-自问自答>7. 自问自答</a><ul><li><a href=#71-为什么要除根号dk>7.1 为什么要除根号dk</a></li></ul></li></ul></nav></div></details></nav><h2 id=0-参考资料>0. 参考资料<a href=#0-参考资料 class=anchor aria-hidden=true>#</a></h2><ul><li>Video <a href="https://www.bilibili.com/video/BV1TZ421j7Ke/?spm_id_from=333.337.search-card.all.click&amp;vd_source=4aacda34aa5e7f3fa73c6456818924d1">动画形式直观解释注意力机制</a></li></ul><h2 id=1-attention机制概述>1. Attention机制概述<a href=#1-attention机制概述 class=anchor aria-hidden=true>#</a></h2><p>Attention机制是Transformer架构的核心,它使模型能够动态地关注输入序列中的不同部分。这种机制允许模型捕捉长距离依赖关系,这在处理长序列时特别重要。</p><h2 id=2-self-attention的基本概念>2. Self-Attention的基本概念<a href=#2-self-attention的基本概念 class=anchor aria-hidden=true>#</a></h2><p>Self-Attention的核心思想是,序列中的每个元素都应该关注整个序列,包括自身。它通过以下三个关键概念实现:</p><ul><li>Query (查询): 当前我们正在处理的元素</li><li>Key (键): 用于与Query进行比较的元素</li><li>Value (值): 实际被聚合的信息</li></ul><p>以NLP任务为例，Value 是前面这些词最终想要加给下一个单词的的偏移量，目标是得到 Q &ndash;> V 的映射，这个映射主要用来压缩前后文信息，加到当前word上。</p><h2 id=3-self-attention的计算过程>3. Self-Attention的计算过程<a href=#3-self-attention的计算过程 class=anchor aria-hidden=true>#</a></h2><p>Self-Attention的计算可以概括为以下步骤：</p><ol><li>对输入进行线性变换,得到Q、K、V矩阵。</li><li>计算Q和K的点积,得到注意力分数。</li><li>对注意力分数进行缩放和softmax归一化。</li><li>用归一化后的分数对V进行加权求和。</li></ol><p>数学表达式为:</p><span class="math math-block text-center" id=h-rh-cb-math-0><img src=/_3377536591665604331.svg alt="mathematical expression or equation"></span><p>其中
<span class="math math-inline" id=h-sc-math-0><img src=/_6420321948663586204.svg alt="mathematical expression or equation">
</span>是键向量的维度，
<span class="math math-inline" id=h-sc-math-1><img src=/_5734958649108525011.svg alt="mathematical expression or equation">
</span>用于缩放以防止点积结果过大。</p><h2 id=4-attention的直观理解>4. Attention的直观理解<a href=#4-attention的直观理解 class=anchor aria-hidden=true>#</a></h2><p>可以将Attention理解为一种软性的字典查找。Query就像是一个搜索词,Keys像是字典中的条目,而Values则是对应的内容。模型通过计算Query和Keys的相似度来决定应该关注哪些Values。</p><h2 id=5-attention的应用示例>5. Attention的应用示例<a href=#5-attention的应用示例 class=anchor aria-hidden=true>#</a></h2><p>在机器翻译中,Attention允许模型在生成每个目标词时动态地关注源句子的不同部分。例如,翻译"The cat sat on the mat"时,在生成"猫"这个词时,模型会更多地关注源句中的"cat"。</p><h2 id=6-attention的变体和扩展>6. Attention的变体和扩展<a href=#6-attention的变体和扩展 class=anchor aria-hidden=true>#</a></h2><p>除了基本的Self-Attention,还有许多变体,如:</p><ul><li>Relative Position Attention: 引入相对位置信息</li><li>Sparse Attention: 通过稀疏化提高效率</li><li>Longformer: 处理更长序列的注意力机制</li></ul><p>总的来说,Attention机制使Transformer能够灵活地处理序列数据,捕捉复杂的上下文关系,这是其在多种NLP任务上取得卓越性能的关键原因。</p><h2 id=7-自问自答>7. 自问自答<a href=#7-自问自答 class=anchor aria-hidden=true>#</a></h2><h3 id=71-为什么要除根号dk>7.1 为什么要除根号dk<a href=#71-为什么要除根号dk class=anchor aria-hidden=true>#</a></h3><ol><li><p>缩放的必要性：</p><p>首先，在Attention计算中，我们对Q和K进行点积操作。当输入的维度d_k较大时，点积的结果可能会变得非常大。这会导致softmax函数的梯度变得极小，造成所谓的梯度消失问题，影响模型的训练。</p></li><li><p>为什么是
<span class="math math-inline" id=h-sc-math-2><img src=/_5734958649108525011.svg alt="mathematical expression or equation"></span></p><p>选择
<span class="math math-inline" id=h-sc-math-3><img src=/_5734958649108525011.svg alt="mathematical expression or equation">
</span>作为缩放因子主要是为了保持方差的稳定性。这里涉及到一些统计学原理：</p><ul><li>假设Q和K中的元素是独立同分布的随机变量，均值为0，方差为1。</li><li>在这种情况下，它们的点积
<span class="math math-inline" id=h-sc-math-4><img src=/_15644524883239298051.svg alt="mathematical expression or equation">
</span>的方差将等于
<span class="math math-inline" id=h-sc-math-5><img src=/_6420321948663586204.svg alt="mathematical expression or equation">
</span>。</li><li>通过除以
<span class="math math-inline" id=h-sc-math-6><img src=/_5734958649108525011.svg alt="mathematical expression or equation">
</span>，我们可以将点积的方差归一化为1。
这种归一化确保了无论输入的维度如何变化，注意力分数的分布都保持相对稳定。</li></ul></li><li><p>为什么不使用其他值</p><ul><li>如果不进行缩放（即除以1），当$d_k$较大时，点积结果可能会非常大，导致softmax后的注意力分布过于集中。</li><li>如果除以$d_k$，可能会使结果变得过小，特别是当d_k较大时，这可能导致梯度过小，影响模型的学习。</li><li>其他的缩放因子（如$d_k^{\frac{1}{3}}$或$2d_k$）可能无法有效地控制方差，或者没有明确的统计学解释。</li></ul></li><li><p>实践经验</p><ul><li>在实际应用中，使用$\sqrt{d_k}$作为缩放因子已经在多个任务和模型中证明了其有效性。它提供了一个很好的平衡点，既能控制方差，又不会过度压缩注意力分数。</li><li>这种缩放方法的理论基础可以追溯到Xavier初始化和He初始化等神经网络权重初始化方法。这些方法同样使用了$\sqrt{d_k}$（n为输入单元数）来保持前向传播时激活值的方差稳定。</li><li>值得注意的是，尽管$\sqrt{d_k}$是一个很好的默认选择，但在某些特定任务或模型结构中，可能会使用略有不同的缩放因子。这取决于具体的应用场景和实验结果。</li></ul><p>总的来说，使用$\sqrt{d_k}$作为缩放因子是基于统计学原理的选择，旨在保持注意力机制在不同维度下的稳定性和有效性。这个选择在理论上有合理的解释，并在实践中证明了其有效性。</p></li></ol><p>疑惑2，为什么当输入的维度d_k较大时，点积的结果可能会变得非常大</p><ol><li>点积的基本性质
首先，让我们回顾一下点积的定义。对于两个向量 a = [a₁, a₂, &mldr;, aₙ] 和 b = [b₁, b₂, &mldr;, bₙ]，它们的点积是：
$a \cdot b = a_1b_1 + a_2b_2 + &mldr; + a_nb_n$</li></ol><div class="page-footer-meta d-flex flex-column flex-md-row justify-content-between"></div><div class="page-nav d-flex flex-column flex-sm-row"><div class="card w-100"><div class="card-body d-flex"><div class="d-flex flex-column justify-content-center"><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-arrow-left" width="20" height="20" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 12h14"/><path d="M5 12l6 6"/><path d="M5 12l6-6"/></svg></div><div class="d-flex flex-column"><div class=text-body-secondary>Prev</div><a href=/docs/mmcv/mmcv-runner/ class="stretched-link text-reset text-decoration-none">MMCV-Runner</a></div></div></div><div class=m-2></div><div class="card text-end w-100"><div class="card-body d-flex justify-content-end"><div class="d-flex flex-column"><div class=text-body-secondary>Next</div><a href=/docs/introduction/introduction/ class="stretched-link text-reset text-decoration-none">introduction</a></div><div class="d-flex flex-column justify-content-center"><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-arrow-right" width="20" height="20" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 12h14"/><path d="M13 18l6-6"/><path d="M13 6l6 6"/></svg></div></div></div></div></main></div></div></div><footer class="footer text-muted"><div class=container-lg><div class=row><div class="col-lg-8 text-center text-lg-start"><ul class=list-inline></ul></div><div class="col-lg-8 text-center text-lg-end"><ul class=list-inline><li class=list-inline-item>Brought to you by <a class=text-muted href=https://thulite.io/>Thulite</a></li></ul></div></div></div></footer><script async src=/js/app.c17553444ec7c62f781ddbaa011948f6d85a1bab49420047d68a2b89852a8b36.js integrity="sha256-wXVTRE7Hxi94HduqARlI9thaG6tJQgBH1ooriYUqizY="></script><script async src=/js/flexsearch.7b25ae2da7ab3cc745d4f8536e3f914f92ea8b1afad96ab9249c160c35e0648c.js integrity="sha256-eyWuLaerPMdF1PhTbj+RT5Lqixr62Wq5JJwWDDXgZIw="></script><script async src=/js/search-modal.0415aa45353ab123a509f6ddc6861549ece898b90872fcf757cd2663041dac96.js integrity="sha256-BBWqRTU6sSOlCfbdxoYVSezomLkIcvz3V80mYwQdrJY="></script></body></html>